# -*- coding: utf-8 -*-
"""EmotionPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lqG4aq4ysVurMyE7fiM1O-XtETq3WIbH
"""


# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt
import os
from pylsl import StreamInlet, resolve_byprop  # Module to receive EEG data
from scipy import signal, stats
import mne
# from tkinter import *


def calculate_output_shape(input_shape, model):
    """
    Print the output shape of each layer to debug dimension issues
    """
    x = tf.zeros((1,) + input_shape)
    for layer in model.layers:
        x = layer(x)
        print(f"{layer.name}: output_shape = {x.shape}")
    return x.shape

def load_h5_model(model_path, desiredSamples):
    """
    Load H5 model with shape debugging
    """
    print(f"Input shape: (4, {desiredSamples})")

    # Create model
    model = keras.Sequential([
        # Input layer
        keras.layers.InputLayer(input_shape=(4, desiredSamples)),
        keras.layers.Reshape((4, desiredSamples, 1), name='reshape'),

        # First Conv Block
        keras.layers.Conv2D(32, (1, 4), strides=(1,1), activation='relu', padding='same', name='conv1'),
        keras.layers.MaxPooling2D((1, 2), name='pool1'),

        # Second Conv Block
        keras.layers.Conv2D(64, (1, 8), strides=(1,1), activation='relu', padding='same', name='conv2'),
        keras.layers.MaxPooling2D((1, 2), name='pool2'),

        # Third Conv Block
        keras.layers.Conv2D(64, (1, 8), strides=(1,1), activation='relu', padding='same', name='conv3'),
        keras.layers.MaxPooling2D((1, 2), name='pool3'),

        # Fourth Conv Block
        keras.layers.Conv2D(64, (1, 64), strides=(1,1), activation='relu', padding='same', name='conv4'),
        keras.layers.MaxPooling2D((1, 2), name='pool4'),

        # Fifth Conv Layer
        keras.layers.Conv2D(64, (1, 8), strides=(1,1), activation='relu', padding='same', name='conv5'),

        # Output layers
        keras.layers.Flatten(name='flatten'),
        keras.layers.Dense(64, activation='relu', name='dense1'),
        keras.layers.Dense(3, activation='linear', name='dense2')
    ])

    # Print shapes before loading weights
    print("\nCalculating layer shapes:")
    final_shape = calculate_output_shape((4, desiredSamples), model)
    print(f"\nFinal flattened shape before dense layer: {final_shape}")

    try:
        # Try loading weights
        model.load_weights(model_path, by_name=True, skip_mismatch=True)

        print("\nModel loaded successfully!")
        return model
    except Exception as e:
        print(f"\nDetailed error: {str(e)}")
        raise Exception("Failed to load H5 model")

# Example usage
if __name__ == "__main__":
    try:
        model_path = "EmotionNetV2.h5"  # Replace with your .h5 file path

        # Based on the error message, let's calculate the required input size
        # 10752 = target flattened size (from error message)
        # 15872 = current flattened size
        # We need to adjust desiredSamples to match these dimensions

        # Try different desiredSamples values
        for test_samples in [256, 384, 512, 768]:
            print(f"\nTrying with desiredSamples = {test_samples}")
            try:
                model = load_h5_model(model_path, test_samples)
                print(f"Success with desiredSamples = {test_samples}")
                model.summary()
                break
            except Exception as e:
                print(f"Failed with {test_samples} samples")
                continue

    except Exception as e:
        print(f"Error: {str(e)}")

fs = 256
inputLength = 10.5 # Length of input in seconds
shiftLength = 5 # Time between epochs
samples = int(shiftLength * fs) # How many samples to gather in every cycle
print(samples)

bufferSize = int(128 * inputLength) # Size of buffer in samples. Enough to hold one set of downsampled input.

buffers = np.zeros((4, bufferSize)) # buffers for each of the four channels

# Push new data onto buffer, removing any old data on the end
def updateBuffer(buffer, newData):
    assert len(newData.shape) == len(buffer.shape) and buffer.shape[0] >= newData.shape[0], "Buffer shape ({}) and new data shape ({}) are not compatible.".format(buffer.shape, newData.shape)
    size = newData.shape[0]
    buffer[:-size] = buffer[size:]
    buffer[-size:] = newData
    return buffer
# Get the streamed data from the Muse. Blue Muse must be streaming.

print('Looking for an EEG stream...')
streams = resolve_byprop('type', 'EEG', timeout=2)
if len(streams) == 0:
    raise RuntimeError('Can\'t find EEG stream.')


# Set active EEG stream to inlet and apply time correction
print("Start acquiring data")
inlet = StreamInlet(streams[0], max_buflen=60, max_chunklen=int(inputLength))
eeg_time_correction = inlet.time_correction()

# Get the stream info and description
info = inlet.info()
description = info.desc()

# Get the sampling frequency
# This is an important value that represents how many EEG data points are
# collected in a second. This influences our frequency band calculation.
# for the Muse 2016, this should always be 256
fs = int(info.nominal_srate())

print("Stream connected.")
print("Sampling frequency: {} points per second".format(fs))

# Begin processing EEG data
print("Processing Muse EEG data...\n")

import time

plt.figure(figsize=(10, 5))  # Create figure outside the loop

for i in range(4):
    start = time.time()
    data, timestamp = inlet.pull_chunk(timeout=5, max_samples=samples)
    t = time.time() - start
    print("Got {} samples in {:.5f} seconds".format(len(data), t))
    eeg = np.array(data).swapaxes(0,1)

    # Downsample
    processedEEG = signal.resample(eeg, int(eeg.shape[1] * (128 / fs)), axis=1)

    # Apply bandpass filter from 4-45Hz
    processedEEG = mne.filter.filter_data(processedEEG, sfreq=128, l_freq=4, h_freq=45, 
                                      filter_length='auto', l_trans_bandwidth='auto', 
                                      h_trans_bandwidth='auto', method='fir', 
                                      phase='zero', fir_window='hamming', verbose=0)

    # Zero mean
    processedEEG -= np.mean(processedEEG, axis=1, keepdims=True)
    if i == 0:
        continue


    # Update buffer
    for channel in range(buffers.shape[0]):
        buffers[channel] = updateBuffer(buffers[channel], processedEEG[channel])

    # Plot updated EEG signal
    plt.clf()  # Clear previous plot
    plt.title("EEG - Iteration {}".format(i + 1))
    plt.plot(buffers[0], label="Tp9")
    plt.plot(buffers[1], label="AF7")
    plt.plot(buffers[2], label="AF8")
    plt.plot(buffers[3], label="Tp10")
    plt.legend()
    plt.pause(0.1)  # Pause briefly to update the plot

print("END")

plt.title("EEG")
plt.plot(buffers[0,:256], label="Tp9")
plt.plot(buffers[1,:256], label="AF7")
plt.plot(buffers[2,:256], label="AF8")
plt.plot(buffers[3,:256], label="Tp10")
plt.legend()
plt.show(block=False)  # Show the plot without blocking

print("wad")


# Get the sampling frequency
fs = int(info.nominal_srate())
print("Sampling frequency: {} Hz".format(fs))



img = plt.imread("EmotionSpace.png")
width = img.shape[1]
height = img.shape[0]
centerX = int(width / 2) -8
centerY = int(height / 2) +8
pixPerValence = centerX / 5
pixPerArousal = centerY / 5

def determine_mood(valence, arousal, dominance):
    if valence >= 5 and arousal >= 5:
        if dominance >= 5:
            return "Mildly Positive & Confident"
        else:
            return "Slightly Positive but Hesitant"
    elif valence >= 5 and arousal < 5:
        if dominance >= 5:
            return "Calm & Neutral"
        else:
            return "Relaxed but Withdrawn"
    elif valence < 5 and arousal >= 5:
        if dominance >= 5:
            return "Frustrated but Assertive"
        else:
            return "Stressed & Overwhelmed"
    else:  # valence < 5 and arousal < 5
        if dominance >= 5:
            return "Indifferent & Passive"
        else:
            return "Sad & Low Energy"



# Example scaling function
def scale_emotions(emotions, target_min=1, target_max=9):
    # Assuming emotions are in range [-1, 1]
    source_min, source_max = -1, 1
    scaled_emotions = (emotions - source_min) * (target_max - target_min) / (source_max - source_min) + target_min
    return scaled_emotions

try:
    # Pull final batch of EEG data
    data, timestamp = inlet.pull_chunk(timeout=5, max_samples=samples)
    eeg = np.array(data).swapaxes(0,1)

    # Downsample
    processedEEG = signal.resample(eeg, int(eeg.shape[1] * (128 / fs)), axis=1)

    # Apply bandpass filter from 4-45Hz
    processedEEG = mne.filter.filter_data(processedEEG, sfreq=128, l_freq=4, h_freq=45, 
                                          filter_length='auto', l_trans_bandwidth='auto', 
                                          h_trans_bandwidth='auto', method='fir', 
                                          phase='zero', fir_window='hamming', verbose=0)

    # Zero mean
    processedEEG -= np.mean(processedEEG, axis=1, keepdims=True)

    print(processedEEG)

    # Update buffer
    for channel in range(buffers.shape[0]):
        buffers[channel] = updateBuffer(buffers[channel], processedEEG[channel])

    # Perform emotion regression analysis
    chunk_size = 256
    num_chunks = buffers.shape[1] // chunk_size  # Total full chunks

    # Store predictions
    emotion_predictions = []

    for i in range(num_chunks):
        start = i * chunk_size
        end = start + chunk_size

        # Extract chunk and reshape for the model
        input_data = buffers[:, start:end]  # Shape (4, 256)
        input_data = np.expand_dims(input_data, axis=0)  # Shape (1, 4, 256)

        # Predict emotions for this chunk
        emotions = model.predict(input_data)
        print("Emotions:", emotions)
        emotions = scale_emotions(emotions)

        # Print raw and scaled emotions for debugging
        print("Raw emotions:", emotions)
        print("Scaled emotions:", emotions)
        
        # Ensure emotions has correct shape
        if emotions.ndim == 1:
            emotions = emotions.reshape(1, -1)  # Convert to (1, 3) if scalar
        elif emotions.shape[-1] != 3:
            print("Unexpected model output shape:", emotions.shape)
            continue

        emotions = np.clip(emotions, 1, 9)  # Clip outliers

        emotion_predictions.append(emotions[0])  # Store predictions

    # Ensure we have valid predictions
    if emotion_predictions:
        # Compute mean across all chunks
        mean_emotions = np.mean(emotion_predictions, axis=0)

        valence = mean_emotions[0]
        arousal = mean_emotions[1]
        dominance = mean_emotions[2]

    print("Final Emotion Averages:")
    print("Valence: {:.2f}".format(valence))
    print("Arousal: {:.2f}".format(arousal))
    print("Dominance: {:.2f}".format(dominance))

    # Determine mood
    end_mood = determine_mood(valence, arousal, dominance)
    print("End Mood:", end_mood)
    x = valence * pixPerValence
    y = (10 - arousal) * pixPerArousal

    # clear_output(wait=True)
    plt.figure(figsize=(10,10))
    plt.imshow(img)

    plt.plot(x, y, color='red', marker='o', markersize=36)
    plt.show()
    # plt.show(block=False)
    # plt.pause(3)
    # plt.close()

    print("Final Emotion Analysis:")
    print("Valence: {:.2f}".format(valence))
    print("Arousal: {:.2f}".format(arousal))
    print("Dominance: {:.2f}".format(dominance))

finally:
    inlet.close_stream()
    print("Stream closed.")